{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from scipy.spatial import cKDTree as KDTree\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from pyvirtualdisplay import Display\n",
    "\n",
    "import csv\n",
    "import cv2\n",
    "import datetime\n",
    "import matplotlib\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "import unidecode\n",
    "import traceback\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridCount=1\n",
    "rois=[]\n",
    "PATH='/home/abhiavk/git/Website-Evolution/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeTaken(startTime, Metric, MetricValue=\"\"):\n",
    "\tprint(Metric.ljust(25,\" \"),datetime.datetime.now()-startTime,\"\\t\\t\",MetricValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_words(txt):\n",
    "    txt=re.sub(\"[^\\w]\",\" \",  txt)\n",
    "    txt=re.sub(\"[0-9]+\",\" \",  txt)\n",
    "    txt=re.sub(\" [a-zA-Z]{1} \",\" \",  txt)\n",
    "    txt=re.sub(\" [a-zA-Z]{2} \",\" \",  txt)\n",
    "    txt=re.sub(\"[ ]+\",\" \",txt)\n",
    "    return txt.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(d):\n",
    "    txt=\"\"\n",
    "    try:\n",
    "        txt+=d.execute_script(\"return document.body.innerText;\")\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        txt+=d.execute_script(\"return document.innerText;\")\n",
    "    except:\n",
    "        pass\n",
    "    words = string_to_words(str(unidecode.unidecode(txt)))\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_count(d):\n",
    "    startTime=datetime.datetime.now()\n",
    "    words=get_words(d)\n",
    "    wordCount=float(len(words))\n",
    "    #timeTaken(startTime,\"Word Count\",wordCount)\n",
    "    return wordCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_body_ratio(soup,wordCount):\n",
    "\n",
    "    startTime=datetime.datetime.now()\n",
    "    headers=[]\n",
    "    for i in range(1,7):\n",
    "        headers+=soup.findAll(\"h\"+str(i))\n",
    "    sizeHeaders=[]\n",
    "    sizeHeaders+=soup.findAll(\"font\",{\"size\":\"3\"})\n",
    "    sizeHeaders+=soup.findAll(\"font\",{\"size\":\"4\"})\n",
    "    sizeHeaders+=soup.findAll(\"font\",{\"size\":\"5\"})\n",
    "    txt=\"\"\n",
    "    for i in headers:\n",
    "        txt+=\" \"+i.text\n",
    "    for i in sizeHeaders:\n",
    "        txt+=\" \"+i.text\n",
    "    words=[]\n",
    "    if len(txt)!=0:\n",
    "        words=string_to_words(str(unidecode.unidecode(txt)))\n",
    "    #print words\n",
    "    try:\n",
    "        headTextCount=float(len(words))\n",
    "    except:\n",
    "        headtextCount=0.0\n",
    "    if wordCount:\n",
    "        textBodyRatio=headTextCount/wordCount\n",
    "    else:\n",
    "        textBodyRatio=0.0\n",
    "    #timeTaken(startTime,\"Text Body Ratio\",textBodyRatio)\n",
    "    return textBodyRatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emph_body_text_percentage(d,bs,wordCount):\n",
    "\n",
    "    #print \"Param3\"\n",
    "    startTime=datetime.datetime.now()\n",
    "    boldText = bs.findAll(\"b\")\n",
    "    words=[]\n",
    "    for i in boldText:\n",
    "        try:\n",
    "            words+= string_to_words(str(unidecode.unidecode(i.text)))\n",
    "        except:\n",
    "            pass\n",
    "    boldWordCount=len(words)\n",
    "    try:\n",
    "        txt=str(unidecode.unidecode(d.execute_script(\"return document.body.innerText\")))\n",
    "    except:\n",
    "        txt=str(unidecode.unidecode(d.execute_script(\"return document.body.textContent\")))\n",
    "    pattern = re.compile(\"!+\")\n",
    "    exclWordCount=len(re.findall(pattern,txt))\n",
    "    words=get_words(d)\n",
    "    capWordCount=0\n",
    "    for i in words:\n",
    "        if i==i.upper():\n",
    "            capWordCount+=1\n",
    "\n",
    "    #print boldWordCount, exclWordCount, capWordCount\n",
    "\n",
    "    emphTextCount=float(boldWordCount + exclWordCount + capWordCount)\n",
    "\n",
    "    if wordCount:\n",
    "        emphTextPercent=(emphTextCount/wordCount)*100.0\n",
    "    else:\n",
    "        emphTextPercent=0.0\n",
    "    #timeTaken(startTime,\"Emph text Percent\",emphTextPercent)\n",
    "    return emphTextPercent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_position_changes(s):\n",
    "    startTime=datetime.datetime.now()\n",
    "    #print \"Param\n",
    "    elem=s.findAll()\n",
    "    prev=\"\"\n",
    "    textPositionChanges=0\n",
    "    for i in elem:\n",
    "        try:\n",
    "            string=str(i[\"style\"])\n",
    "            if \"text-align:\"in string:\n",
    "                align=string.split(\"text-align:\")[1]\n",
    "                position=align.split(\";\")[0].strip()\n",
    "                if position!=prev:\n",
    "                    textPositionChanges+=1\n",
    "                    prev=position\n",
    "        except:\n",
    "            pass\n",
    "    #timeTaken(startTime,\"Text Positional Changes\",textPositionChanges)\n",
    "    return textPositionChanges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_clusters(d,bs):\n",
    "\n",
    "\t#print \"Param5\"\n",
    "\tstartTime=datetime.datetime.now()\n",
    "\ttableText= bs.findAll(\"td\")+bs.findAll(\"table\")\n",
    "\tparaText = bs.findAll(\"p\")\n",
    "\ttextClusters=len(tableText)+len(paraText)\n",
    "\t#timeTaken(startTime,\"Text Clusters\",textClusters)\n",
    "\treturn textClusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_visible_links(d,bs):\n",
    "\n",
    "\t#print \"Param6\"\n",
    "\tstartTime=datetime.datetime.now()\n",
    "\tlinks=bs.findAll(\"a\")\n",
    "\tvisibleLinkCount=0\n",
    "\tfor i in links:\n",
    "\t\tif i.text != \"\":\n",
    "\t\t\tvisibleLinkCount+=1\n",
    "\t#timeTaken(startTime,\"Visible Links\",visibleLinkCount)\n",
    "\treturn visibleLinkCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_size(d):\n",
    "\n",
    "\t#print \"Param7\"\n",
    "\tstartTime=datetime.datetime.now()\n",
    "\tscriptToExecute = \"\tvar performance = \twindow.performance ||\\\n",
    "\t\t\t\t\t\t\t\t\t\t\twindow.mozPerformance ||\\\n",
    "\t\t\t\t\t\t\t\t\t\t\twindow.msPerformance ||\\\n",
    "\t\t\t\t\t\t\t\t\t \t\twindow.webkitPerformance || {};\\\n",
    "\t\t\t\t\t\tvar network \t= \tperformance.getEntries() || {};\\\n",
    "\t\t\t\t\t\treturn network;\"\n",
    "\tnetworkData = d.execute_script(scriptToExecute)\n",
    "\tpageSize=0\n",
    "\tfor i in networkData:\n",
    "\t\ttry:\n",
    "\t\t\tpageSize+=float(i[u'transferSize'])\n",
    "\t\texcept:\n",
    "\t\t\tpass\n",
    "\tpageSize=float(pageSize)/1024.0\n",
    "\t#timeTaken(startTime,\"Page Size\",pageSize)\n",
    "\treturn pageSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graphics_percent(d,pageSize):\n",
    "\n",
    "\t#print \"Param8\"\n",
    "\tstartTime=datetime.datetime.now()\n",
    "\tscriptToExecute = \"var performance = window.performance || window.mozPerformance || window.msPerformance || window.webkitPerformance || {}; var network = performance.getEntries() || {}; return network;\"\n",
    "\tnetworkData = d.execute_script(scriptToExecute)\n",
    "\tgraphicsSize=0.0\n",
    "\tfor i in networkData:\n",
    "\t\ttry:\n",
    "\t\t\tif i[u'initiatorType']== u'script' or i[u'initiatorType']==u'img' or i['initiatorType']== u'css':\n",
    "\t\t\t\tgraphicsSize+=float(i[u'transferSize'])\n",
    "\t\texcept:\n",
    "\t\t\tpass\n",
    "\tgraphicsSize=float(graphicsSize)/1024.0\n",
    "\n",
    "\tif pageSize==0:\n",
    "\t\tgraphicsPercent=0.0\n",
    "\telse:\n",
    "\t\tgraphicsPercent=graphicsSize*100.0/pageSize\n",
    "\t#timeTaken(startTime,\"Graphic Size\",graphicsSize)\n",
    "\treturn graphicsPercent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graphics_count(d,bs):\n",
    "\tstartTime=datetime.datetime.now()\n",
    "\t#print \"Param9\"\n",
    "\tstyleSteets=bs.findAll(\"style\")\n",
    "\tscripts=bs.findAll(\"script\")\n",
    "\timages=d.execute_script(\"return document.images;\")\n",
    "\tgraphicsCount=len(styleSteets)+len(images)+len(scripts)\n",
    "\t#timeTaken(startTime,\"Graphics Count\",graphicsCount)\n",
    "\treturn  graphicsCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_count(image):\n",
    "    startTime=datetime.datetime.now()\n",
    "    use_colors = matplotlib.colors.cnames\n",
    "    named_colors = {k: tuple(map(int, (v[1:3], v[3:5], v[5:7]), 3*(16,))) for k, v in use_colors.items()}\n",
    "    ncol = len(named_colors)\n",
    "    no_match = named_colors['purple']\n",
    "\n",
    "    color_tuples = list(named_colors.values())\n",
    "    color_tuples.append(no_match)\n",
    "    color_tuples = np.array(color_tuples)\n",
    "\n",
    "    color_names = list(named_colors)\n",
    "    color_names.append('no match')\n",
    "\n",
    "    tree = KDTree(color_tuples[:-1])\n",
    "\n",
    "    tolerance = np.inf\n",
    "    dist, idx = tree.query(image, distance_upper_bound=tolerance)\n",
    "\n",
    "    colCounts = np.bincount(idx.ravel(), None, ncol+1).tolist()\n",
    "    colNames  = color_names\n",
    "\n",
    "    colors=[]\n",
    "    for i in range(len(color_names)):\n",
    "        colors.append([colCounts[i],color_names[i]])\n",
    "\n",
    "    colors.sort(reverse=True)\n",
    "\n",
    "    colorCount=0\n",
    "    for color in colors:\n",
    "        if color[0]>=7864: #1% of the pixels\n",
    "            colorCount+=1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    #timeTaken(startTime,\"Color Count\",colorCount)\n",
    "    return colorCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_font_count(d,bs):\n",
    "    startTime=datetime.datetime.now()\n",
    "    divCount=len(bs.findAll(\"div\"))\n",
    "    diffFont=set([])\n",
    "    for i in range(divCount):\n",
    "        fontStr=\"\"\n",
    "        script='return document.getElementsByTagName(\"div\")['+str(i)+'][\"style\"]'\n",
    "        fontStr+=d.execute_script(script+'[\"font\"];')+\"font\"\n",
    "        fontStr+=d.execute_script(script+'[\"fontDisplay\"];')+\"fontDisplay\"\n",
    "        fontStr+=d.execute_script(script+'[\"fontFamily\"];')+\"fontFamily\"\n",
    "        fontStr+=d.execute_script(script+'[\"fontFeatureSettings\"];')+\"fontFeatureSettings\"\n",
    "        fontStr+=d.execute_script(script+'[\"fontKerning\"];')+\"fontKerning\"\n",
    "        fontStr+=d.execute_script(script+'[\"fontSize\"];')+\"fontSize\"\n",
    "        fontStr+=d.execute_script(script+'[\"fontStretch\"];')+\"fontStretch\"\n",
    "        fontStr+=d.execute_script(script+'[\"fontStyle\"];')+\"fontStyle\"\n",
    "        fontStr+=d.execute_script(script+'[\"fontVariant\"];')+\"fontVariant\"\n",
    "        fontStr+=d.execute_script(script+'[\"fontVariantCaps\"];')+\"fontVariantCaps\"\n",
    "        fontStr+=d.execute_script(script+'[\"fontVariantEastAsian\"];')+\"fontVariantEastAsian\"\n",
    "        fontStr+=d.execute_script(script+'[\"fontVariantLigatures\"];')+\"fontVariantLigatures\"\n",
    "        fontStr+=d.execute_script(script+'[\"fontVariantNumeric\"];')+\"fontVariantNumeric\"\n",
    "        fontStr+=d.execute_script(script+'[\"fontVariationSettings\"];')+\"fontVariationSettings\"\n",
    "        fontStr+=d.execute_script(script+'[\"fontWeight\"];')+\"fontWeight\"\n",
    "\n",
    "        diffFont.add(fontStr)\n",
    "    #print(diffFont)\n",
    "    fontCount=len(diffFont)-1 # -1 for empty font (default font)\n",
    "    #timeTaken(startTime,\"Font Count\",fontCount)\n",
    "    return fontCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getColorfullness(image):\n",
    "    startTime=datetime.datetime.now()\n",
    "    (B, G, R) = cv2.split(image.astype(\"float\"))\n",
    "    rg = np.absolute(R - G)\n",
    "    yb = np.absolute(0.5 * (R + G) - B)\n",
    "    (rbMean, rbStd) = (np.mean(rg), np.std(rg))\n",
    "    (ybMean, ybStd) = (np.mean(yb), np.std(yb))\n",
    "    stdRoot = np.sqrt((rbStd ** 2) + (ybStd ** 2))\n",
    "    meanRoot = np.sqrt((rbMean ** 2) + (ybMean ** 2))\n",
    "    colourFullness = stdRoot + (0.3 * meanRoot)\n",
    "    #timeTaken(startTime,\"Colourfullness\",colourFullness)\n",
    "    return colourFullness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVisualComplexity(image,num):\n",
    "    startTime=datetime.datetime.now()\n",
    "    year=sys.argv[-2]\n",
    "    def splitImage(inImg):\n",
    "        h,w = inImg.shape[0], inImg.shape[1]\n",
    "        off1X=0\n",
    "        off1Y=0\n",
    "        off2X=0\n",
    "        off2Y=0\n",
    "        if w >= h:  #split X\n",
    "            off1X=0\n",
    "            off2X=int(w/2)\n",
    "            img1 = inImg[0:h, 0:off2X]\n",
    "            img2 = inImg[0:h, off2X:w]\n",
    "        else:       #split Y\n",
    "            off1Y=0\n",
    "            off2Y=int(h/2)\n",
    "            img1 = inImg[0:off2Y, 0:w]\n",
    "            img2 = inImg[off2Y:h, 0:w]\n",
    "        return off1X,off1Y,img1, off2X,off2Y,img2\n",
    "    def qt(inImg, minStd, minSize, offX, offY):\n",
    "        global gridCount\n",
    "        global rois\n",
    "        h,w = inImg.shape[0], inImg.shape[1]\n",
    "        m,s = cv2.meanStdDev(inImg)\n",
    "        if s>=minStd and max(h,w)>minSize:\n",
    "            oX1,oY1,im1, oX2,oY2,im2 = splitImage(inImg)\n",
    "            gridCount+=1\n",
    "            qt(im1, minStd, minSize, offX+oX1, offY+oY1)\n",
    "            qt(im2, minStd, minSize, offX+oX2, offY+oY2)\n",
    "        else:\n",
    "            rois.append([offX,offY,w,h,m,s])\n",
    "\n",
    "    global gridCount\n",
    "    global rois\n",
    "\n",
    "    gridCount=1\n",
    "    rois=[]\n",
    "    offX, offY=0,0\n",
    "    minDev        = 10.0\n",
    "    minSz         = 20\n",
    "\n",
    "    #cv2.imshow('Start Image',image)\n",
    "    h,w = image.shape[0], image.shape[1]\n",
    "    m,s = cv2.meanStdDev(image)\n",
    "    qt(image,minDev,minSz,offX,offY)\n",
    "    imgOut=image\n",
    "    for e in rois:\n",
    "        col=255\n",
    "        if e[5]<minDev:\n",
    "            col=0\n",
    "        cv2.rectangle(imgOut, (e[0],e[1]), (e[0]+e[2],e[1]+e[3]), col, 1)\n",
    "    cv2.imwrite(PATH+'webScreenshot/'+str(year)+'/screenshot'+str(num)+'_Quad.png',imgOut)\n",
    "    #cv2.imshow('Quad Image',imgOut)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n",
    "    visualComplexity=gridCount#((gridCount*1.0)/(1024.0*768.0))**-1\n",
    "    #timeTaken(startTime,\"Visual Complexity\",visualComplexity)\n",
    "    return visualComplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setDriverOptions():\n",
    "    options \t\t\t\t= Options()\n",
    "    options.binary_location = \"webEvPy/bin/chromium-browser\"\n",
    "    chrome_driver_binary\t= \"webEvPy/bin/chromedriver\"\n",
    "    #options.add_argument(\"--headless\")\n",
    "    return\twebdriver.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMetrics(urlFile):\n",
    "    num=urlFile['id']\n",
    "    url=urlFile['urls']\n",
    "    #print(url,num)\n",
    "    startTime \t\t= datetime.datetime.now()\n",
    "    textFilename\t= PATH+\"yearMetrics/CorruptUrls\"+str(year)+\".txt\"\n",
    "    csvFilename\t\t= PATH+\"yearMetrics/tempMpUrlMetrics\"+str(year)+\".csv\"\n",
    "    try:\n",
    "        driver\t\t\t= setDriverOptions()\n",
    "        driver.get(url)\n",
    "        try:\n",
    "            style=driver.find_element_by_xpath(\"//div[@id='wm-ipp-base']\")\n",
    "            style=driver.execute_script(\"arguments[0].style.display = 'none'; return arguments[0];\", style)\n",
    "        except:\n",
    "            print(\"Hiding wb toolbar error\")\n",
    "            pass\n",
    "        driver.implicitly_wait(10)\n",
    "        time.sleep(5)\n",
    "        driver.set_window_size(1024, 768)\n",
    "        WebDriverWait(driver, timeout=15).until(lambda x: x.find_elements_by_tag_name('body'))\n",
    "        \n",
    "        imagePath=PATH+'webScreenshot/'+str(year)+'/screenshot'+str(num)+'.png'\n",
    "        #print(imagePath)\n",
    "        driver.save_screenshot(imagePath)\n",
    "        image = cv2.imread(imagePath)\n",
    "        imageGrey = cv2.imread(imagePath,0)\n",
    "        page_source=driver.page_source\n",
    "        soup=BeautifulSoup(page_source,'html.parser')\n",
    "        #---------------------------------------------------#\n",
    "        #--------- Web Metric Calculation ------------------#\n",
    "        #---------------------------------------------------#\n",
    "        wordCount\t\t\t\t= get_word_count(driver)#Parameter 1\n",
    "        textBodyRatio\t\t\t= get_text_body_ratio(soup,wordCount)#Parameter 2\n",
    "        emphTextPercent\t\t\t= get_emph_body_text_percentage(driver,soup,wordCount)#Parameter 3\n",
    "        textPositionalChanges\t= get_text_position_changes(soup)#Parameter 4\n",
    "        textClusters\t\t\t= get_text_clusters(driver,soup)#Parameter 5\n",
    "        visibleLinks\t\t\t= get_visible_links(driver,soup)#Parameter 6\n",
    "        pageSize\t\t\t\t= get_page_size(driver)#Parameter 7\n",
    "        graphicsPercent\t\t\t= get_graphics_percent(driver,pageSize)#Parameter 8\n",
    "        graphicsCount \t\t\t= get_graphics_count(driver,soup)#Parameter 9\n",
    "        colorCount\t\t\t\t= get_color_count(image)#Parameter 10\n",
    "        fontCount\t\t\t\t= get_font_count(driver,soup)#Parameter 11\n",
    "        colourFullness\t\t\t= getColorfullness(image)#Parameter 12\n",
    "        visualComplexity\t\t= getVisualComplexity(imageGrey,num)\n",
    "\n",
    "\n",
    "        tempMetrics=[\n",
    "                    num,\\\n",
    "                    wordCount,\\\n",
    "                    textBodyRatio,\\\n",
    "                    emphTextPercent,\\\n",
    "                    textPositionalChanges,\\\n",
    "                    textClusters,\\\n",
    "                    visibleLinks,\\\n",
    "                    pageSize,\\\n",
    "                    graphicsPercent,\\\n",
    "                    graphicsCount,\\\n",
    "                    colorCount,\\\n",
    "                    fontCount,\\\n",
    "                    colourFullness,\\\n",
    "                    visualComplexity,\\\n",
    "                    url\n",
    "            ]\n",
    "        line=tempMetrics\n",
    "        csvFile\t\t= open(csvFilename,\"a+\")\n",
    "        csvWriter\t= csv.writer(csvFile)\n",
    "        csvWriter.writerow(line)\n",
    "        csvFile.close()\n",
    "        driver.close()\n",
    "    except:\n",
    "        print(traceback.format_exc())\n",
    "        try:\n",
    "            driver.close()\n",
    "        except:\n",
    "            print(\"###Error : Couldn't close driver\")\n",
    "        print(\"Error scraping the Url\")\n",
    "        f2\t\t\t= open(textFilename,\"a+\")\n",
    "        f2.write(num+\",\"+url+\"\\n\")\n",
    "        f2.close()\n",
    "    print((datetime.datetime.now()-startTime).seconds,\"\\t\",datetime.datetime.now().replace(microsecond=0),\"\\t\",year,num,url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(filename,year=\"\"):\n",
    "    \n",
    "    fields\t\t\t= [\"slno\",\"p1\",\"p2\",\"p3\",\"p4\",\"p5\",\"p6\",\"p7\",\"p8\",\"p9\",\"p10\",\"p11\",\"p12\",\"p13\",\"url\"]\n",
    "    csvFilename\t\t= \"yearMetrics/tempMpUrlMetrics\"+str(year)+\".csv\"\n",
    "    csvFile\t\t\t= open(csvFilename,\"a+\")\n",
    "    csvWriter\t\t= csv.writer(csvFile)\n",
    "    csvWriter.writerow(fields)\n",
    "    csvFile.close()\n",
    "    \n",
    "    fields\t\t\t= [\"id\",\"urls\"]\n",
    "    csvFilename\t\t= \"yearMetrics/CorruptUrls\"+str(year)+\".csv\"\n",
    "    csvFile\t\t\t= open(csvFilename,\"a+\")\n",
    "    csvWriter\t\t= csv.writer(csvFile)\n",
    "    csvWriter.writerow(fields)\n",
    "    csvFile.close()\n",
    "    \n",
    "    csvFile\t\t\t= open(filename,\"r\")\n",
    "    urlFile\t\t\t= csv.DictReader(csvFile)\n",
    "    driver\t\t\t= setDriverOptions()\n",
    "    \"\"\"\n",
    "    manager \t\t= mp.Manager()\n",
    "    urls \t\t\t= manager.list()\n",
    "    results \t\t= manager.list()\n",
    "    pool \t\t\t= mp.Pool(1)\n",
    "    results \t\t= pool.map_async(getMetrics, urlFile)\n",
    "    while not results.ready():\n",
    "        pass\n",
    "    \"\"\"\n",
    "    for url in urlFile:\n",
    "        getMetrics(url)\n",
    "    csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hiding wb toolbar error\n",
      "16 \t 2019-05-12 01:10:11 \t 2000 1 https://web.archive.org/web/20000101000000/http://www.adbusters.com\n",
      "22 \t 2019-05-12 01:10:34 \t 2000 2 https://web.archive.org/web/20000101000000/http://www.hungersite.com\n",
      "29 \t 2019-05-12 01:11:03 \t 2000 3 https://web.archive.org/web/20000101000000/http://www.aclu.org\n",
      "15 \t 2019-05-12 01:11:18 \t 2000 4 https://web.archive.org/web/20000101000000/http://www.protest.net\n",
      "13 \t 2019-05-12 01:11:31 \t 2000 5 https://web.archive.org/web/20000101000000/http://www.actionnetwork.org\n",
      "11 \t 2019-05-12 01:11:43 \t 2000 6 https://web.archive.org/web/20000101000000/http://www.backspace.org/iod/iod4Winupdates.html\n",
      "15 \t 2019-05-12 01:11:58 \t 2000 7 https://web.archive.org/web/20000101000000/http://www.sfmoma.org/EXHIB/viola/fr_splash.html\n",
      "13 \t 2019-05-12 01:12:12 \t 2000 8 https://web.archive.org/web/20000101000000/http://easylife.org\n",
      "14 \t 2019-05-12 01:12:27 \t 2000 9 https://web.archive.org/web/20000101000000/http://www.netomat.net\n",
      "14 \t 2019-05-12 01:12:42 \t 2000 10 https://web.archive.org/web/20000101000000/http://phoneme.walkerart.org\n",
      "16 \t 2019-05-12 01:12:58 \t 2000 11 https://web.archive.org/web/20000101000000/http://www.videofarm.com\n",
      "Hiding wb toolbar error\n",
      "18 \t 2019-05-12 01:13:16 \t 2000 12 https://web.archive.org/web/20000101000000/http://www.atomfilms.com\n",
      "Hiding wb toolbar error\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-130-914ecd78e0ec>\", line 20, in getMetrics\n",
      "    WebDriverWait(driver, timeout=15).until(lambda x: x.find_elements_by_tag_name('body'))\n",
      "  File \"/usr/local/lib/python3.6/site-packages/selenium/webdriver/support/wait.py\", line 80, in until\n",
      "    raise TimeoutException(message, screen, stacktrace)\n",
      "selenium.common.exceptions.TimeoutException: Message: \n",
      "\n",
      "\n",
      "Error scraping the Url\n",
      "50 \t 2019-05-12 01:14:07 \t 2000 13 https://web.archive.org/web/20000101000000/http://www.nationalgeographic.com/congotrek/\n",
      "Hiding wb toolbar error\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-130-914ecd78e0ec>\", line 20, in getMetrics\n",
      "    WebDriverWait(driver, timeout=15).until(lambda x: x.find_elements_by_tag_name('body'))\n",
      "  File \"/usr/local/lib/python3.6/site-packages/selenium/webdriver/support/wait.py\", line 71, in until\n",
      "    value = method(self._driver)\n",
      "  File \"<ipython-input-130-914ecd78e0ec>\", line 20, in <lambda>\n",
      "    WebDriverWait(driver, timeout=15).until(lambda x: x.find_elements_by_tag_name('body'))\n",
      "  File \"/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py\", line 546, in find_elements_by_tag_name\n",
      "    return self.find_elements(by=By.TAG_NAME, value=name)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py\", line 1007, in find_elements\n",
      "    'value': value})['value'] or []\n",
      "  File \"/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py\", line 321, in execute\n",
      "    self.error_handler.check_response(response)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py\", line 241, in check_response\n",
      "    raise exception_class(message, screen, stacktrace, alert_text)\n",
      "selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None\n",
      "Message: unexpected alert open: {Alert text : Congratulations! \n",
      "\n",
      "You are the California winner for September 23rd\n",
      "\n",
      "Please select a prize and enter your email to claim.}\n",
      "  (Session info: chrome=73.0.3683.86)\n",
      "  (Driver info: chromedriver=2.41.578700 (2f1ed5f9343c13f73144538f15c00b370eda6706),platform=Linux 4.18.0-10-generic x86_64)\n",
      "\n",
      "\n",
      "Error scraping the Url\n",
      "22 \t 2019-05-12 01:14:30 \t 2000 14 https://web.archive.org/web/20000101000000/http://www.ifilm.com\n",
      "Hiding wb toolbar error\n",
      "20 \t 2019-05-12 01:14:50 \t 2000 15 https://web.archive.org/web/20000101000000/http://www.wirebreak.com\n",
      "22 \t 2019-05-12 01:15:12 \t 2000 16 https://web.archive.org/web/20000101000000/http://www.babycenter.com\n",
      "Hiding wb toolbar error\n",
      "22 \t 2019-05-12 01:15:35 \t 2000 17 https://web.archive.org/web/20000101000000/http://www.amazon.com\n",
      "Hiding wb toolbar error\n",
      "27 \t 2019-05-12 01:16:03 \t 2000 18 https://web.archive.org/web/20000101000000/http://www.etoys.com\n",
      "19 \t 2019-05-12 01:16:22 \t 2000 19 https://web.archive.org/web/20000101000000/http://www.gear.com\n",
      "15 \t 2019-05-12 01:16:37 \t 2000 20 https://web.archive.org/web/20000101000000/http://www.mobshop.com\n",
      "18 \t 2019-05-12 01:16:56 \t 2000 21 https://web.archive.org/web/20000101000000/http://cafe.utne.com/cafe\n",
      "24 \t 2019-05-12 01:17:21 \t 2000 22 https://web.archive.org/web/20000101000000/http://slashdot.org\n",
      "13 \t 2019-05-12 01:17:35 \t 2000 23 https://web.archive.org/web/20000101000000/http://www.mtbr.com\n",
      "13 \t 2019-05-12 01:17:48 \t 2000 24 https://web.archive.org/web/20000101000000/http://www.craigslist.org\n",
      "Hiding wb toolbar error\n",
      "19 \t 2019-05-12 01:18:07 \t 2000 25 https://web.archive.org/web/20000101000000/http://www.icq.com\n",
      "27 \t 2019-05-12 01:18:35 \t 2000 26 https://web.archive.org/web/20000101000000/http://www.wordcentral.com\n",
      "15 \t 2019-05-12 01:18:50 \t 2000 27 https://web.archive.org/web/20000101000000/http://www.pbs.org/wgbh/aso\n",
      "13 \t 2019-05-12 01:19:03 \t 2000 28 https://web.archive.org/web/20000101000000/http://www.pbs.org/wgbh/cultureshock\n",
      "16 \t 2019-05-12 01:19:20 \t 2000 29 https://web.archive.org/web/20000101000000/http://vector.cshl.org/dnaftb\n",
      "15 \t 2019-05-12 01:19:35 \t 2000 30 https://web.archive.org/web/20000101000000/http://www.artsednet.getty.edu\n",
      "13 \t 2019-05-12 01:19:49 \t 2000 31 https://web.archive.org/web/20000101000000/http://www.paulsmith.co.uk\n",
      "11 \t 2019-05-12 01:20:01 \t 2000 32 https://web.archive.org/web/20000101000000/http://www.toddoldham.com\n",
      "12 \t 2019-05-12 01:20:14 \t 2000 33 https://web.archive.org/web/20000101000000/http://www.fuk.co.uk\n",
      "12 \t 2019-05-12 01:20:26 \t 2000 34 https://web.archive.org/web/20000101000000/http://www.hintmag.com\n",
      "Hiding wb toolbar error\n",
      "19 \t 2019-05-12 01:20:46 \t 2000 35 https://web.archive.org/web/20000101000000/http://www.centuryinshoes.com\n",
      "17 \t 2019-05-12 01:21:03 \t 2000 36 https://web.archive.org/web/20000101000000/http://www.gomez.com\n",
      "Hiding wb toolbar error\n",
      "20 \t 2019-05-12 01:21:23 \t 2000 37 https://web.archive.org/web/20000101000000/http://www.paypal.com\n",
      "16 \t 2019-05-12 01:21:40 \t 2000 38 https://web.archive.org/web/20000101000000/http://www.island.com\n",
      "14 \t 2019-05-12 01:21:54 \t 2000 39 https://web.archive.org/web/20000101000000/http://www.metamarkets.com\n",
      "14 \t 2019-05-12 01:22:09 \t 2000 40 https://web.archive.org/web/20000101000000/http://www.nextcard.com\n",
      "15 \t 2019-05-12 01:22:25 \t 2000 41 https://web.archive.org/web/20000101000000/http://www.gamespy.com\n",
      "15 \t 2019-05-12 01:22:40 \t 2000 42 https://web.archive.org/web/20000101000000/http://www.shockwave.com\n",
      "19 \t 2019-05-12 01:22:59 \t 2000 43 https://web.archive.org/web/20000101000000/http://www.gamasutra.com\n",
      "22 \t 2019-05-12 01:23:22 \t 2000 44 https://web.archive.org/web/20000101000000/http://happypuppy.com\n",
      "24 \t 2019-05-12 01:23:46 \t 2000 45 https://web.archive.org/web/20000101000000/http://www.station.sony.com\n",
      "26 \t 2019-05-12 01:24:13 \t 2000 46 https://web.archive.org/web/20000101000000/http://thriveonline.com\n",
      "Hiding wb toolbar error\n",
      "19 \t 2019-05-12 01:24:33 \t 2000 47 https://web.archive.org/web/20000101000000/http://www.intelihealth.com\n",
      "16 \t 2019-05-12 01:24:49 \t 2000 48 https://web.archive.org/web/20000101000000/http://adam.com\n",
      "Hiding wb toolbar error\n",
      "16 \t 2019-05-12 01:25:06 \t 2000 49 https://web.archive.org/web/20000101000000/http://www.onhealth.com\n",
      "16 \t 2019-05-12 01:25:23 \t 2000 50 https://web.archive.org/web/20000101000000/http://www.respectprotect.com\n",
      "30 \t 2019-05-12 01:25:53 \t 2000 51 https://web.archive.org/web/20000101000000/http://www.theonion.com\n",
      "13 \t 2019-05-12 01:26:07 \t 2000 52 https://web.archive.org/web/20000101000000/http://www.mcsweeneys.net\n",
      "19 \t 2019-05-12 01:26:26 \t 2000 53 https://web.archive.org/web/20000101000000/http://www.comedycentral.com\n",
      "15 \t 2019-05-12 01:26:42 \t 2000 54 https://web.archive.org/web/20000101000000/http://gwbush.com\n",
      "Hiding wb toolbar error\n",
      "15 \t 2019-05-12 01:26:58 \t 2000 55 https://web.archive.org/web/20000101000000/http://www.leisuretown.com\n",
      "16 \t 2019-05-12 01:27:14 \t 2000 56 https://web.archive.org/web/20000101000000/http://food.epicurious.com\n",
      "15 \t 2019-05-12 01:27:29 \t 2000 57 https://web.archive.org/web/20000101000000/http://bluemountain.com\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hiding wb toolbar error\n",
      "19 \t 2019-05-12 01:27:48 \t 2000 58 https://web.archive.org/web/20000101000000/http://www.garden.com\n",
      "15 \t 2019-05-12 01:28:03 \t 2000 59 https://web.archive.org/web/20000101000000/http://marthastewart.com\n",
      "16 \t 2019-05-12 01:28:20 \t 2000 60 https://web.archive.org/web/20000101000000/http://www.swoon.com\n",
      "Hiding wb toolbar error\n",
      "20 \t 2019-05-12 01:28:41 \t 2000 61 https://web.archive.org/web/20000101000000/http://www.atomfilms.com\n",
      "14 \t 2019-05-12 01:28:55 \t 2000 62 https://web.archive.org/web/20000101000000/http://www.imdb.com\n",
      "23 \t 2019-05-12 01:29:19 \t 2000 63 https://web.archive.org/web/20000101000000/http://www.script-o-rama.com\n",
      "Hiding wb toolbar error\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-130-914ecd78e0ec>\", line 20, in getMetrics\n",
      "    WebDriverWait(driver, timeout=15).until(lambda x: x.find_elements_by_tag_name('body'))\n",
      "  File \"/usr/local/lib/python3.6/site-packages/selenium/webdriver/support/wait.py\", line 71, in until\n",
      "    value = method(self._driver)\n",
      "  File \"<ipython-input-130-914ecd78e0ec>\", line 20, in <lambda>\n",
      "    WebDriverWait(driver, timeout=15).until(lambda x: x.find_elements_by_tag_name('body'))\n",
      "  File \"/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py\", line 546, in find_elements_by_tag_name\n",
      "    return self.find_elements(by=By.TAG_NAME, value=name)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py\", line 1007, in find_elements\n",
      "    'value': value})['value'] or []\n",
      "  File \"/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py\", line 321, in execute\n",
      "    self.error_handler.check_response(response)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py\", line 241, in check_response\n",
      "    raise exception_class(message, screen, stacktrace, alert_text)\n",
      "selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None\n",
      "Message: unexpected alert open: {Alert text : Congratulations! \n",
      "\n",
      "You are the California winner for September 23rd\n",
      "\n",
      "Please select a prize and enter your email to claim.}\n",
      "  (Session info: chrome=73.0.3683.86)\n",
      "  (Driver info: chromedriver=2.41.578700 (2f1ed5f9343c13f73144538f15c00b370eda6706),platform=Linux 4.18.0-10-generic x86_64)\n",
      "\n",
      "\n",
      "Error scraping the Url\n",
      "22 \t 2019-05-12 01:29:41 \t 2000 64 https://web.archive.org/web/20000101000000/http://www.ifilm.com\n",
      "15 \t 2019-05-12 01:29:56 \t 2000 65 https://web.archive.org/web/20000101000000/http://www.proteintv.com\n",
      "16 \t 2019-05-12 01:30:13 \t 2000 66 https://web.archive.org/web/20000101000000/http://www.napster.com\n",
      "16 \t 2019-05-12 01:30:29 \t 2000 67 https://web.archive.org/web/20000101000000/http://www.farmclub.com\n",
      "29 \t 2019-05-12 01:30:58 \t 2000 68 https://web.archive.org/web/20000101000000/http://www.launch.com\n",
      "Hiding wb toolbar error\n",
      "19 \t 2019-05-12 01:31:18 \t 2000 69 https://web.archive.org/web/20000101000000/http://www.sputnik7.com\n",
      "12 \t 2019-05-12 01:31:31 \t 2000 70 https://web.archive.org/web/20000101000000/http://www.wiredplanet.com\n",
      "Hiding wb toolbar error\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-130-914ecd78e0ec>\", line 20, in getMetrics\n",
      "    WebDriverWait(driver, timeout=15).until(lambda x: x.find_elements_by_tag_name('body'))\n",
      "  File \"/usr/local/lib/python3.6/site-packages/selenium/webdriver/support/wait.py\", line 80, in until\n",
      "    raise TimeoutException(message, screen, stacktrace)\n",
      "selenium.common.exceptions.TimeoutException: Message: \n",
      "\n",
      "\n",
      "Error scraping the Url\n",
      "31 \t 2019-05-12 01:32:02 \t 2000 71 https://web.archive.org/web/20000101000000/http://www.medianews.org\n",
      "19 \t 2019-05-12 01:32:22 \t 2000 72 https://web.archive.org/web/20000101000000/http://www.abcnews.go.com\n",
      "13 \t 2019-05-12 01:32:36 \t 2000 73 https://web.archive.org/web/20000101000000/http://www.mediaattack.com\n",
      "Hiding wb toolbar error\n",
      "19 \t 2019-05-12 01:32:55 \t 2000 74 https://web.archive.org/web/20000101000000/http://www.news.com\n",
      "Hiding wb toolbar error\n",
      "22 \t 2019-05-12 01:33:18 \t 2000 75 https://web.archive.org/web/20000101000000/http://www.wsj.com\n",
      "12 \t 2019-05-12 01:33:31 \t 2000 76 https://web.archive.org/web/20000101000000/http://www.cockybastard.com\n",
      "13 \t 2019-05-12 01:33:44 \t 2000 77 https://web.archive.org/web/20000101000000/http://www.diaryland.com\n",
      "26 \t 2019-05-12 01:34:10 \t 2000 78 https://web.archive.org/web/20000101000000/http://www.kottke.org\n",
      "11 \t 2019-05-12 01:34:22 \t 2000 79 https://web.archive.org/web/20000101000000/http://www.maganda.org\n",
      "11 \t 2019-05-12 01:34:33 \t 2000 80 https://web.archive.org/web/20000101000000/http://www.metababy.com\n",
      "Hiding wb toolbar error\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-130-914ecd78e0ec>\", line 20, in getMetrics\n",
      "    WebDriverWait(driver, timeout=15).until(lambda x: x.find_elements_by_tag_name('body'))\n",
      "  File \"/usr/local/lib/python3.6/site-packages/selenium/webdriver/support/wait.py\", line 71, in until\n",
      "    value = method(self._driver)\n",
      "  File \"<ipython-input-130-914ecd78e0ec>\", line 20, in <lambda>\n",
      "    WebDriverWait(driver, timeout=15).until(lambda x: x.find_elements_by_tag_name('body'))\n",
      "  File \"/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py\", line 546, in find_elements_by_tag_name\n",
      "    return self.find_elements(by=By.TAG_NAME, value=name)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py\", line 1007, in find_elements\n",
      "    'value': value})['value'] or []\n",
      "  File \"/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py\", line 321, in execute\n",
      "    self.error_handler.check_response(response)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py\", line 241, in check_response\n",
      "    raise exception_class(message, screen, stacktrace, alert_text)\n",
      "selenium.common.exceptions.UnexpectedAlertPresentException: Alert Text: None\n",
      "Message: unexpected alert open: {Alert text : Congratulations Facebook User!\n",
      "\n",
      "You are the California winner for June 30th\n",
      "\n",
      "Please select a prize and enter your email to claim.}\n",
      "  (Session info: chrome=73.0.3683.86)\n",
      "  (Driver info: chromedriver=2.41.578700 (2f1ed5f9343c13f73144538f15c00b370eda6706),platform=Linux 4.18.0-10-generic x86_64)\n",
      "\n",
      "\n",
      "Error scraping the Url\n",
      "22 \t 2019-05-12 01:34:55 \t 2000 81 https://web.archive.org/web/20000101000000/http://www.politics.com\n",
      "17 \t 2019-05-12 01:35:13 \t 2000 82 https://web.archive.org/web/20000101000000/http://www.findlaw.com\n",
      "Hiding wb toolbar error\n",
      "33 \t 2019-05-12 01:35:46 \t 2000 83 https://web.archive.org/web/20000101000000/http://www.allpolitics.com\n",
      "15 \t 2019-05-12 01:36:02 \t 2000 84 https://web.archive.org/web/20000101000000/http://www.nolo.com\n",
      "18 \t 2019-05-12 01:36:20 \t 2000 85 https://web.archive.org/web/20000101000000/http://www.politicsonline.com\n",
      "21 \t 2019-05-12 01:36:41 \t 2000 86 https://web.archive.org/web/20000101000000/http://www.nerve.com\n",
      "23 \t 2019-05-12 01:37:04 \t 2000 87 https://web.archive.org/web/20000101000000/http://www.slashdot.org\n",
      "26 \t 2019-05-12 01:37:30 \t 2000 88 https://web.archive.org/web/20000101000000/http://www.feedmag.com\n",
      "Hiding wb toolbar error\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-130-914ecd78e0ec>\", line 20, in getMetrics\n",
      "    WebDriverWait(driver, timeout=15).until(lambda x: x.find_elements_by_tag_name('body'))\n",
      "  File \"/usr/local/lib/python3.6/site-packages/selenium/webdriver/support/wait.py\", line 80, in until\n",
      "    raise TimeoutException(message, screen, stacktrace)\n",
      "selenium.common.exceptions.TimeoutException: Message: \n",
      "\n",
      "\n",
      "Error scraping the Url\n",
      "31 \t 2019-05-12 01:38:01 \t 2000 89 https://web.archive.org/web/20000101000000/http://www.medianews.org\n",
      "26 \t 2019-05-12 01:38:28 \t 2000 90 https://web.archive.org/web/20000101000000/http://www.salon.com\n",
      "15 \t 2019-05-12 01:38:43 \t 2000 91 https://web.archive.org/web/20000101000000/http://www.lostandfoundsound.com\n",
      "12 \t 2019-05-12 01:38:56 \t 2000 92 https://web.archive.org/web/20000101000000/http://www.bbc.co.uk/radio1\n",
      "13 \t 2019-05-12 01:39:09 \t 2000 93 https://web.archive.org/web/20000101000000/http://www.greenwitch.com\n",
      "15 \t 2019-05-12 01:39:25 \t 2000 94 https://web.archive.org/web/20000101000000/http://www.kiisfmi.com\n",
      "13 \t 2019-05-12 01:39:38 \t 2000 95 https://web.archive.org/web/20000101000000/http://www.kroq.com\n",
      "20 \t 2019-05-12 01:39:59 \t 2000 96 https://web.archive.org/web/20000101000000/http://www.culture.gouv.fr/culture/arcnat/lascaux/en/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 \t 2019-05-12 01:40:16 \t 2000 97 https://web.archive.org/web/20000101000000/http://www.mbayaq.org\n",
      "13 \t 2019-05-12 01:40:30 \t 2000 98 https://web.archive.org/web/20000101000000/http://vector.cshl.org\n",
      "12 \t 2019-05-12 01:40:42 \t 2000 99 https://web.archive.org/web/20000101000000/http://www.explorescience.com\n",
      "12 \t 2019-05-12 01:40:55 \t 2000 100 https://web.archive.org/web/20000101000000/http://www.madsci.org\n",
      "Hiding wb toolbar error\n",
      "28 \t 2019-05-12 01:41:24 \t 2000 101 https://web.archive.org/web/20000101000000/http://www.evite.com\n",
      "14 \t 2019-05-12 01:41:38 \t 2000 102 https://web.archive.org/web/20000101000000/http://www.epinions.com\n",
      "12 \t 2019-05-12 01:41:50 \t 2000 103 https://web.archive.org/web/20000101000000/http://www.kozmo.com\n",
      "Hiding wb toolbar error\n",
      "16 \t 2019-05-12 01:42:07 \t 2000 104 https://web.archive.org/web/20000101000000/http://www.stamps.com\n",
      "20 \t 2019-05-12 01:42:27 \t 2000 105 https://web.archive.org/web/20000101000000/http://www.webvan.com\n",
      "15 \t 2019-05-12 01:42:42 \t 2000 106 https://web.archive.org/web/20000101000000/http://www.espn.go.com\n",
      "20 \t 2019-05-12 01:43:03 \t 2000 107 https://web.archive.org/web/20000101000000/http://www.foxsports.com\n",
      "16 \t 2019-05-12 01:43:20 \t 2000 108 https://web.archive.org/web/20000101000000/http://www.quokka.com\n",
      "Hiding wb toolbar error\n",
      "16 \t 2019-05-12 01:43:36 \t 2000 109 https://web.archive.org/web/20000101000000/http://www.remembertheaba.com\n",
      "23 \t 2019-05-12 01:43:59 \t 2000 110 https://web.archive.org/web/20000101000000/http://www.sportsjones.com\n",
      "Hiding wb toolbar error\n",
      "19 \t 2019-05-12 01:44:19 \t 2000 111 https://web.archive.org/web/20000101000000/http://www.msnbc.com\n",
      "22 \t 2019-05-12 01:44:41 \t 2000 112 https://web.archive.org/web/20000101000000/http://www.cnn.com\n",
      "18 \t 2019-05-12 01:44:59 \t 2000 113 https://web.archive.org/web/20000101000000/http://www.hbo.com\n",
      "16 \t 2019-05-12 01:45:16 \t 2000 114 https://web.archive.org/web/20000101000000/http://www.mtv.com\n",
      "25 \t 2019-05-12 01:45:41 \t 2000 115 https://web.archive.org/web/20000101000000/http://www.oxygen.com\n",
      "Hiding wb toolbar error\n",
      "18 \t 2019-05-12 01:46:00 \t 2000 116 https://web.archive.org/web/20000101000000/http://www.outsidemag.com\n",
      "18 \t 2019-05-12 01:46:18 \t 2000 117 https://web.archive.org/web/20000101000000/http://travel.discovery.com\n",
      "57 \t 2019-05-12 01:47:16 \t 2000 118 https://web.archive.org/web/20000101000000/http://www.citysync.com\n",
      "Hiding wb toolbar error\n",
      "17 \t 2019-05-12 01:47:33 \t 2000 119 https://web.archive.org/web/20000101000000/http://www.previewtravel.com\n",
      "12 \t 2019-05-12 01:47:46 \t 2000 120 https://web.archive.org/web/20000101000000/http://www.sierraclub.org\n",
      "15 \t 2019-05-12 01:48:01 \t 2000 121 https://web.archive.org/web/20000101000000/http://www.google.com\n",
      "Hiding wb toolbar error\n",
      "15 \t 2019-05-12 01:48:17 \t 2000 122 https://web.archive.org/web/20000101000000/http://www.activebuyersguide.com\n",
      "15 \t 2019-05-12 01:48:33 \t 2000 123 https://web.archive.org/web/20000101000000/http://babelfish.altavista.com\n",
      "17 \t 2019-05-12 01:48:50 \t 2000 124 https://web.archive.org/web/20000101000000/http://www.desktop.com\n",
      "23 \t 2019-05-12 01:49:14 \t 2000 125 https://web.archive.org/web/20000101000000/http://www.station.sony.com\n",
      "15 \t 2019-05-12 01:49:29 \t 2000 126 https://web.archive.org/web/20000101000000/http://www.scholastic.com\n",
      "15 \t 2019-05-12 01:49:44 \t 2000 127 https://web.archive.org/web/20000101000000/http://www.africam.com\n",
      "19 \t 2019-05-12 01:50:04 \t 2000 128 https://web.archive.org/web/20000101000000/http://www.mamamedia.com\n",
      "12 \t 2019-05-12 01:50:16 \t 2000 129 https://web.archive.org/web/20000101000000/http://www.math.com\n",
      "14 \t 2019-05-12 01:50:31 \t 2000 130 https://web.archive.org/web/20000101000000/http://www.thinkquest.org\n"
     ]
    }
   ],
   "source": [
    "filename=\"yearUrlWb/Wb2000.csv\"\n",
    "year=\"2000\"\n",
    "main(filename,year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "st=datetime.datetime.now()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(datetime.datetime.now()-st).seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm webScreenshot/*/*.png\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=setDriverOptions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://web.archive.org/web/20010118215400/http://www.half.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_class_name(\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "style=driver.find_element_by_xpath(\"//div[@id='wm-ipp-base']\")\n",
    "style=driver.execute_script(\"arguments[0].style.display = 'none'; return arguments[0];\", style)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " <div class=\"owl-prev\" style=\"display: none;\">prev</div>  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
